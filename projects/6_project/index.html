<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Fun With Diffusion Models | Cyprian Zander </title> <meta name="author" content="Cyprian Zander"> <meta name="description" content="December 12, 2025"> <meta name="keywords" content="machine-learning, computer-science, berkeley, uc-berkeley, portfolio, research, data-science, software-engineering, academic, publications, artificial-intelligence, deep-learning, neural-networks, python, programming, algorithms, statistics, mathematics, cs-student, undergraduate, research-assistant, github, open-source, technical-writing, academic-website, personal-website, student-portfolio, cs180, cs61a, cs61b, cs70, cs188, cs189, launchpad, berkeley-launchpad, startup, entrepreneurship, technology, innovation, stem, education, university, california, bay-area, silicon-valley"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favico.ico?ba4125972f729e5643234e8f9a65339e"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zanderfilet.github.io/projects/6_project/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Cyprian</span> Zander </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/books/">bookshelf </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/photography/">photography </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Fun With Diffusion Models</h1> <p class="post-description">December 12, 2025</p> </header> <article> <h3 id="overview">Overview</h3> <p>In this project, I implemented generative models for image synthesis and denoising. In the first stage of the project, I worked with pretrained diffusion models, by using a DeepFloyd IF model with my own generated prompt embeddings. Using the pretrained model, I wrote sampling loops to produce images from noise, then extended the work to test out inpainting methods and optical illusions (like the visual anagram in this project’s cover picture). Later, I built generative models from scratch by training neural networks on MNIST. One of these models is a single-step denoising UNet trained to map noisy images to clean digits, which I then extended to a flow-matching model conditioned on noisy inputs and timesteps. I implemented the UNet architecture using down- and upsampling blocks with a loss objective to predict flow between noise and data distributions.</p> <hr> <h3 id="part-a-the-power-of-diffusion-models">Part A: The Power of Diffusion Models</h3> <h5 id="part-0-setup">Part 0: Setup</h5> <p>To start out, I tested some prompt embeddings on the pretrained DeepFloyd model. The following text prompts were used to generate text embeddings:</p> <p><code class="language-plaintext highlighter-rouge">text a high quality picture an oil painting of a snowy mountain village a photo of the amalfi coast a photo of a man a photo of a hipster barista a photo of a dog an oil painting of people around a campfire an oil painting of an old man a lithograph of waterfalls a lithograph of a skull a man wearing a hat a high quality photo a rocket ship a pencil long-stemmed flowers strewn on the hood of a classic Porsche a family of four sitting in a ski lift a green tennis court</code>.</p> <p>The last three prompts are my own.</p> <p>I used a random seed (101) and upsampled the images from 64x64 to 256x256 using DeepFloyd’s pretrained stage II super-resolution model. For each of the below images, the output is the sampled output from 20, 50, and 100 steps from left to right.</p> <h6 id="sampling-results">Sampling Results</h6> <p><strong>Prompt 1: a lithograph of waterfalls</strong></p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/1-480.webp 480w,/assets/img/cs180/p5/part0/1-800.webp 800w,/assets/img/cs180/p5/part0/1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="waterfall_20" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/5-480.webp 480w,/assets/img/cs180/p5/part0/5-800.webp 800w,/assets/img/cs180/p5/part0/5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="waterfall_50" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/9-480.webp 480w,/assets/img/cs180/p5/part0/9-800.webp 800w,/assets/img/cs180/p5/part0/9-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/9.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="waterfall_100" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center"></p> <p>Across all of these images, the waterfalls are clearly recognizable, although adherence to the lithographic style is rather somewhat limited. Despite none of these samples reminding of true lithographies, the samples with higher step counts do seem to approach the idea of a drawing a more closely than the 20 step count image, which reminds more of an animated picture.</p> <p><strong>Prompt 2: long-stemmed flowers strewn on the hood of a classic Porsche</strong></p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/2-480.webp 480w,/assets/img/cs180/p5/part0/2-800.webp 800w,/assets/img/cs180/p5/part0/2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p_20" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/6-480.webp 480w,/assets/img/cs180/p5/part0/6-800.webp 800w,/assets/img/cs180/p5/part0/6-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/6.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p_50" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/10-480.webp 480w,/assets/img/cs180/p5/part0/10-800.webp 800w,/assets/img/cs180/p5/part0/10-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/10.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p_100" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center"></p> <p>All of these renderings clearly display a Porsche, as indicated by the headlights and logo. However, the second iteration seemed to fail with the task of placing the flowers on the hood of the car and instead generated a flowery hedge behind the car. It seems that the 100 iteration image best adheres to the prompt, since it also incorporates the detail that the flowers are supposed to be long-stemmed. Curiously, all samples imagined a pale green vehicle, potentially hinting at some bias in the dataset regarding the green surroundings flowers are typically found in.</p> <p><strong>Prompt 3: a family of four sitting in a ski lift</strong></p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/3-480.webp 480w,/assets/img/cs180/p5/part0/3-800.webp 800w,/assets/img/cs180/p5/part0/3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="f_20" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/7-480.webp 480w,/assets/img/cs180/p5/part0/7-800.webp 800w,/assets/img/cs180/p5/part0/7-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/7.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="f_50" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/11-480.webp 480w,/assets/img/cs180/p5/part0/11-800.webp 800w,/assets/img/cs180/p5/part0/11-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/11.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="f_100" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center"></p> <p>These images also closely adhere to the prompt provided, although only the 100 step example gets the number of people in the ski lift correct. Also notable is that all people were generated with helmets on, but none are correspondingly wearing skis or snowboards.</p> <p><strong>Prompt 4: a green tennis court</strong></p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/4-480.webp 480w,/assets/img/cs180/p5/part0/4-800.webp 800w,/assets/img/cs180/p5/part0/4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t_20" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/8-480.webp 480w,/assets/img/cs180/p5/part0/8-800.webp 800w,/assets/img/cs180/p5/part0/8-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/8.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t_50" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part0/12-480.webp 480w,/assets/img/cs180/p5/part0/12-800.webp 800w,/assets/img/cs180/p5/part0/12-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part0/12.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t_100" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center"></p> <p>In this example, it seems that the model struggled with the combination of green coloring of a tennis court, presumably because tennis courts typically are not green, so the model had issues with correctly displaying the lines on a tennis court and the placement of the net.</p> <h5 id="part-1-sampling-loops">Part 1: Sampling Loops</h5> <h5 id="11-implementing-the-forward-process">1.1: Implementing the Forward Process</h5> <p>In the first stage of implementing the diffusion model, I defined the forward diffusion process. The forward diffusion process gradually transforms a clean image (x_0) into noise by scaling the signal and adding Gaussian noise. At timestep (t), the image (x_t) is sampled by</p> <p>[ q(x_t \mid x_0) = \mathcal{N}!\left(x_t;\ \sqrt{\bar{\alpha}_t}\, x_0,\ (1 - \bar{\alpha}_t)\mathbf{I}\right), ]</p> <p>which is equivalent to</p> <p>[ x_t = \sqrt{\bar{\alpha}_t}\, x_0 + \sqrt{1 - \bar{\alpha}_t}\, \varepsilon, \quad \varepsilon \sim \mathcal{N}(0, \mathbf{I}). ]</p> <p>where (\bar{\alpha}_t) is the cumulative product of the noise schedule up to timestep (t). As (t) increases, (\bar{\alpha}_t \to 0), and (x_t) becomes dominated by Gaussian noise.</p> <p>You can see my code for my implementation of the <code class="language-plaintext highlighter-rouge">forward(im, t)</code>`.</p> <p>Here is the Berkeley campanile at noise level [250, 500, 750].</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/a-480.webp 480w,/assets/img/cs180/p5/part1/a-800.webp 800w,/assets/img/cs180/p5/part1/a-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/a.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="250" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/b-480.webp 480w,/assets/img/cs180/p5/part1/b-800.webp 800w,/assets/img/cs180/p5/part1/b-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/b.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="500" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part2/c-480.webp 480w,/assets/img/cs180/p5/part2/c-800.webp 800w,/assets/img/cs180/p5/part2/c-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part2/c.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="750" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center"></p> <h5 id="12-classical-denoising">1.2: Classical Denoising</h5> <p>To evaluate how difficult diffusion denoising is, I first applied a classical Gaussian blur to noisy images at timesteps (t \in {250, 500, 750}). Gaussian filtering smooths high-frequency noise but cannot recover lost structure, so as the noise level increases, the images become increasingly blurred without meaningful reconstruction.</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/a1-480.webp 480w,/assets/img/cs180/p5/part1/a1-800.webp 800w,/assets/img/cs180/p5/part1/a1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/a1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c250" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/a2-480.webp 480w,/assets/img/cs180/p5/part1/a2-800.webp 800w,/assets/img/cs180/p5/part1/a2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/a2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c250d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">\(t=250)</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/b1-480.webp 480w,/assets/img/cs180/p5/part1/b1-800.webp 800w,/assets/img/cs180/p5/part1/b1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/b1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c500" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/b2-480.webp 480w,/assets/img/cs180/p5/part1/b2-800.webp 800w,/assets/img/cs180/p5/part1/b2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/b2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c500d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">\(t=500)</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/c1-480.webp 480w,/assets/img/cs180/p5/part1/c1-800.webp 800w,/assets/img/cs180/p5/part1/c1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/c1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/c2-480.webp 480w,/assets/img/cs180/p5/part1/c2-800.webp 800w,/assets/img/cs180/p5/part1/c2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/c2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">\(t=750)</p> <h5 id="13-one-step-denoising">1.3: One-Step Denoising</h5> <p>For the 3 noisy images from 1.2 (t = [250, 500, 750]): Use your forward function to add noise to your Campanile. Estimate the noise in the new noisy image, by passing it through stage_1.unet Remove the noise from the noisy image to obtain an estimate of the original image. Visualize the original image, the noisy image, and the estimate of the original image</p> <p>In this step, I used <code class="language-plaintext highlighter-rouge">stage_1.unet</code>, a pretrained, timestep-conditioned UNet, to estimate the Gaussian noise present in a noisy image. Given a noisy image (x_t), the timestep (t), and a text prompt embedding, the UNet predicts the noise (\varepsilon) that was added during the forward process, which I then appropriately scaled and removed to recover an estimate of the original image (x_0).</p> <p>Below is the original campanile, the noisy campanile at variable $t$ noise levels, and the corresponding one-step denoised campanile using the model.</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/a1-480.webp 480w,/assets/img/cs180/p5/part1/a1-800.webp 800w,/assets/img/cs180/p5/part1/a1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/a1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c250" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/a2-480.webp 480w,/assets/img/cs180/p5/part1/a2-800.webp 800w,/assets/img/cs180/p5/part1/a2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/a2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c250d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/a3-480.webp 480w,/assets/img/cs180/p5/part1/a3-800.webp 800w,/assets/img/cs180/p5/part1/a3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/a3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c250c" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">\(t=250)</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/b1-480.webp 480w,/assets/img/cs180/p5/part1/b1-800.webp 800w,/assets/img/cs180/p5/part1/b1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/b1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c500" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/b2-480.webp 480w,/assets/img/cs180/p5/part1/b2-800.webp 800w,/assets/img/cs180/p5/part1/b2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/b2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c500d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/b3-480.webp 480w,/assets/img/cs180/p5/part1/b3-800.webp 800w,/assets/img/cs180/p5/part1/b3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/b3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c500c" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">\(t=500)</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/c1-480.webp 480w,/assets/img/cs180/p5/part1/c1-800.webp 800w,/assets/img/cs180/p5/part1/c1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/c1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/c2-480.webp 480w,/assets/img/cs180/p5/part1/c2-800.webp 800w,/assets/img/cs180/p5/part1/c2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/c2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/c3-480.webp 480w,/assets/img/cs180/p5/part1/c3-800.webp 800w,/assets/img/cs180/p5/part1/c3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/c3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750c" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">\(t=750)</p> <p>As we can see, the denoising UNet is much better at projecting the image onto the natural image manifold, but the sharpness worsens with more noise.</p> <h5 id="14-iterative-denoising">1.4: Iterative Denoising</h5> <p>One-step denoising tries to recover a clean image (x_0) directly from a noisy sample (x_t), but diffusion models are designed to denoise gradually by repeatedly stepping from a noisier timestep to a less noisy one. Because running all (T=1000) steps is expensive, I used a strided schedule and denoised only at those timesteps.</p> <p>At each iteration we have an image (x_t) at timestep (t=\texttt{strided_timesteps}[i]), and we want to move to a less noisy timestep (t’=\texttt{strided_timesteps}[i+1]). I first used the pretrained <code class="language-plaintext highlighter-rouge">stage_1.unet</code> (conditioned on (t) and the text embedding) to estimate the noise (\hat{\varepsilon}), then form an estimate of the clean image:</p> <p>[ \hat{x}_0 \;=\; \frac{x_t - \sqrt{1-\bar{\alpha}_t}\,\hat{\varepsilon}}{\sqrt{\bar{\alpha}_t}}. ]</p> <p>Then we update toward (t’) using the iterative denoising rule, which is like linearly interpolating between signal and noise:</p> <p>[ x_{t’} \;=\; \sqrt{\bar{\alpha}<em>{t’}}\,\hat{x}_0 \;+\; \sqrt{1-\bar{\alpha}</em>{t’}}\,\hat{\varepsilon} \;+\; \sigma(t,t’)\,z, ]</p> <p>where (z\sim \mathcal{N}(0,\mathbf{I})). Repeating this update over the timesteps gradually projects the sample onto the natural image manifold, producing a much cleaner result than single-step denoising or Gaussian blur.</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/690-480.webp 480w,/assets/img/cs180/p5/part1/690-800.webp 800w,/assets/img/cs180/p5/part1/690-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/690.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t690" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/540-480.webp 480w,/assets/img/cs180/p5/part1/540-800.webp 800w,/assets/img/cs180/p5/part1/540-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/540.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t540" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/390-480.webp 480w,/assets/img/cs180/p5/part1/390-800.webp 800w,/assets/img/cs180/p5/part1/390-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/390.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t390" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/240-480.webp 480w,/assets/img/cs180/p5/part1/240-800.webp 800w,/assets/img/cs180/p5/part1/240-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/240.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t240" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/90-480.webp 480w,/assets/img/cs180/p5/part1/90-800.webp 800w,/assets/img/cs180/p5/part1/90-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/90.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="t90" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">From left to right, iterative denoising at timesteps \(690, 540, 390, 240, 90)</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/og-480.webp 480w,/assets/img/cs180/p5/part1/og-800.webp 800w,/assets/img/cs180/p5/part1/og-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/og.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="og" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/iter-480.webp 480w,/assets/img/cs180/p5/part1/iter-800.webp 800w,/assets/img/cs180/p5/part1/iter-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/iter.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="iter" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/1s-480.webp 480w,/assets/img/cs180/p5/part1/1s-800.webp 800w,/assets/img/cs180/p5/part1/1s-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/1s.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="1s" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/gb-480.webp 480w,/assets/img/cs180/p5/part1/gb-800.webp 800w,/assets/img/cs180/p5/part1/gb-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/gb.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="gb" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">Original, iterative, one-step, original with Gaussian blur</p> <h5 id="15-diffusion-model-sampling">1.5: Diffusion Model Sampling</h5> <p>Diffusion models can also be used as generative models by starting from pure Gaussian noise and iteratively denoising it. By setting <code class="language-plaintext highlighter-rouge">i_start = 0</code> and initializing <code class="language-plaintext highlighter-rouge">im_noisy</code> with random noise, the iterative denoising process progressively removes noise according to the learned diffusion dynamics, guided by the text prompt embedding. This procedure transforms unstructured noise into a coherent image consistent with the prompt. In this example, I used the prompt embedding for “a high quality photo,” demonstrating how diffusion models generate images from scratch.</p> <div class="row"> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/d1-480.webp 480w,/assets/img/cs180/p5/part1/d1-800.webp 800w,/assets/img/cs180/p5/part1/d1-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/d1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/d2-480.webp 480w,/assets/img/cs180/p5/part1/d2-800.webp 800w,/assets/img/cs180/p5/part1/d2-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/d2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750d" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/d3-480.webp 480w,/assets/img/cs180/p5/part1/d3-800.webp 800w,/assets/img/cs180/p5/part1/d3-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/d3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750c" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/d4-480.webp 480w,/assets/img/cs180/p5/part1/d4-800.webp 800w,/assets/img/cs180/p5/part1/d4-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/d4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750c" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/cs180/p5/part1/d5-480.webp 480w,/assets/img/cs180/p5/part1/d5-800.webp 800w,/assets/img/cs180/p5/part1/d5-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/cs180/p5/part1/d5.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="c750c" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p class="text-center">Five generated samples from the prompt 'a high quality photo'</p> <h5 id="16-classifier-free-guidance-cfg">1.6: Classifier-Free Guidance (CFG)</h5> <p>The unguided samples from the previous section look a bit nonsensical because, without strong conditioning, the denoising trajectory is only loosely constrained. Many different images are plausible under the model’s prior, and small errors in the predicted noise compound across iterative steps. With a weak prompt like the previous one (or effectively “null” conditioning), the model often drifts toward generic textures or unstable compositions instead of a coherent natural image.</p> <p>Classifier-Free Guidance fixes this by explicitly steering the denoiser using both an unconditional and a conditional noise prediction. At each timestep I ran the UNet twice to get (\varepsilon_u), a noise estimate with the unconditional prompt <code class="language-plaintext highlighter-rouge">""</code> and (\varepsilon_c), noise estimate with the conditional prompt embedding. Then, these can be combined using the CFG rule:</p> <p>[ \varepsilon \;=\; \varepsilon_u + \gamma(\varepsilon_c - \varepsilon_u), ]</p> <p>where (\gamma) controls guidance strength. When (\gamma &gt; 1), the update amplifies the direction that moves the sample toward satisfying the text condition, producing more coherent images at the cost of reduced diversity. This guided (\varepsilon) is then used in the same iterative denoising update as before.</p> <p>Implement the iterative_denoise_cfg function Show 5 images of “a high quality photo” with a CFG scale of gamma = 7. Now this prompt becomes a condition (but fairly weak) to generate conditional noise! You will use your customized prompts as stronger conditions in part 1.7 - part 1.9.</p> <h5 id="17-image-to-image-translation">1.7: Image-to-image Translation</h5> <p>Edits of the Campanile image, using the given prompt at noise levels [1, 3, 5, 7, 10, 20] with the conditional text prompt “a high quality photo” Edits of 2 of your own test images, using the same procedure.</p> <h5 id="171-editing-hand-drawn-and-web-images">1.7.1: Editing Hand-Drawn and Web Images</h5> <p>1 image from the web of your choice, edited using the above method for noise levels [1, 3, 5, 7, 10, 20] (and whatever additional noise levels you want) 2 hand drawn images, edited using the above method for noise levels [1, 3, 5, 7, 10, 20] (and whatever additional noise levels you want)</p> <h5 id="172-inpainting">1.7.2: Inpainting</h5> <p>A properly implemented inpaint function The Campanile inpainted (feel free to use your own mask) 2 of your own images edited (come up with your own mask) look at the results from this paper for inspiration</p> <h5 id="173-text-conditional-image-to-image-translation">1.7.3: Text-Conditional Image-to-image Translation</h5> <p>Edits of the Campanile, using the given prompt at noise levels [1, 3, 5, 7, 10, 20] Edits of 2 of your own test images, using the same procedure</p> <h5 id="18-visual-anagrams">1.8: Visual Anagrams</h5> <p>Correctly implemented visual_anagrams function 2 illusions of your choice that change appearance when you flip it upside down (feel free to take inspirations from this page).</p> <h5 id="19-hybrid-images">1.9: Hybrid Images</h5> <p>Correctly implemented make_hybrids function 2 hybrid images of your choosing (feel free to take inspirations from this page).</p> <h3 id="part-b-flow-matching-from-scratch">Part B: Flow Matching from Scratch</h3> <h5 id="part-1-training-a-single-step-denoising-unet">Part 1: Training a Single-Step Denoising UNet</h5> <h5 id="11-implementing-the-unet">1.1: Implementing the UNet</h5> <h5 id="12-using-the-unet-to-train-a-denoiser">1.2: Using the UNet to Train a Denoiser</h5> <p>A visualization of the noising process using</p> <h5 id="121-training">1.2.1: Training</h5> <p>A training loss curve plot every few iterations during the whole training process of . Sample results on the test set with noise level 0.5 after the first and the 5-th epoch (staff solution takes ~3 minutes for 5 epochs on a Colab T4 GPU).</p> <h5 id="122-out-of-distribution-testing">1.2.2: Out-of-Distribution Testing</h5> <p>Sample results on the test set with out-of-distribution noise levels after the model is trained. Keep the same image and vary</p> <h5 id="123-denoising-pure-noise">1.2.3: Denoising Pure Noise</h5> <p>A training loss curve plot every few iterations during the whole training process that denoises pure noise. Sample results on pure noise after the first and the 5-th epoch. A brief description of the patterns observed in the generated outputs and explanations for why they may exist.</p> <h5 id="part-2-training-a-flow-matching-model">Part 2: Training a Flow Matching Model</h5> <h5 id="21-adding-time-conditioning-to-unet">2.1: Adding Time Conditioning to UNet</h5> <h5 id="22-training-the-unet">2.2: Training the UNet</h5> <h5 id="23-sampling-from-the-unet">2.3: Sampling from the UNet</h5> <p>A training loss curve plot for the time-conditioned UNet over the whole training process.</p> <h5 id="24-adding-class-conditioning-to-unet">2.4: Adding Class-Conditioning to UNet</h5> <p>Sampling results from the time-conditioned UNet for 1, 5, and 10 epochs. The results should not be perfect, but reasonably good. (Optional for CS180, required for CS280A) Check the Bells and Whistles if you want to make it better!</p> <h5 id="25-training-the-unet">2.5: Training the UNet</h5> <p>A training loss curve plot for the class-conditioned UNet over the whole training process.</p> <h5 id="26-sampling-from-the-unet">2.6: Sampling from the UNet</h5> <p>Sampling results from the class-conditioned UNet for 1, 5, and 10 epochs. Class-conditioning lets us converge faster, hence why we only train for 10 epochs. Generate 4 instances of each digit as shown above. Can we get rid of the annoying learning rate scheduler? Simplicity is the best. Please try to maintain the same performance after removing the exponential learning rate scheduler. Show your visualization after training without the scheduler and provide a description of what you did to compensate for the loss of the scheduler.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Cyprian Zander. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>